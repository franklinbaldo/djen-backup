"""Backfill engine — scan historical dates per tribunal with 60-empty-day stop rule.

For each tribunal, scans backward one day at a time.  When 60 consecutive
*authoritative* empties are observed the tribunal is marked stopped and
skipped on future runs.  Errors and timeouts never count as empty.
"""

from __future__ import annotations

import asyncio
import json
import time
from dataclasses import dataclass, field
from datetime import UTC, date, datetime, timedelta
from typing import TYPE_CHECKING

import httpx
import structlog

from djen_backup.archive import (
    CircuitBreaker,
    upload_absent_marker,
    upload_zip,
)
from djen_backup.djen import DJENNotFound, download_zip, get_caderno_url
from djen_backup.state import ItemStatus, State

if TYPE_CHECKING:
    from pathlib import Path

log = structlog.get_logger()

STOP_THRESHOLD = 60

# ── Per-tribunal progress ────────────────────────────────────────────


@dataclass
class TribunalProgress:
    """Backfill progress for a single tribunal."""

    cursor_date: date
    empty_streak: int = 0
    stopped: bool = False
    last_hit_date: date | None = None
    last_checked_at: str | None = None
    last_result: str | None = None  # "hit" | "empty" | "error"

    def to_dict(self) -> dict[str, object]:
        return {
            "cursor_date": self.cursor_date.isoformat(),
            "empty_streak": self.empty_streak,
            "stopped": self.stopped,
            "last_hit_date": self.last_hit_date.isoformat() if self.last_hit_date else None,
            "last_checked_at": self.last_checked_at,
            "last_result": self.last_result,
        }

    @classmethod
    def from_dict(cls, data: dict[str, object]) -> TribunalProgress:
        cursor_raw = data.get("cursor_date")
        if not isinstance(cursor_raw, str):
            msg = "missing cursor_date"
            raise ValueError(msg)

        last_hit_raw = data.get("last_hit_date")
        last_hit = date.fromisoformat(last_hit_raw) if isinstance(last_hit_raw, str) else None

        last_checked = data.get("last_checked_at")
        last_result = data.get("last_result")

        raw_streak = data.get("empty_streak", 0)
        streak = int(raw_streak) if isinstance(raw_streak, (int, float, str)) else 0

        return cls(
            cursor_date=date.fromisoformat(cursor_raw),
            empty_streak=streak,
            stopped=bool(data.get("stopped", False)),
            last_hit_date=last_hit,
            last_checked_at=str(last_checked) if last_checked else None,
            last_result=str(last_result) if last_result else None,
        )


# ── Backfill state ───────────────────────────────────────────────────


class BackfillState:
    """Per-tribunal backfill progress tracking with JSON persistence.

    All mutation methods are protected by an asyncio.Lock.
    """

    def __init__(self) -> None:
        self._tribunals: dict[str, TribunalProgress] = {}
        self._lock = asyncio.Lock()

    async def get_or_init(self, tribunal: str, start_date: date) -> TribunalProgress:
        """Return existing progress or create a new one starting at *start_date*."""
        async with self._lock:
            if tribunal not in self._tribunals:
                self._tribunals[tribunal] = TribunalProgress(cursor_date=start_date)
            return self._tribunals[tribunal]

    async def record_hit(self, tribunal: str, d: date) -> None:
        """Record a successful download (resets empty streak)."""
        async with self._lock:
            prog = self._tribunals[tribunal]
            prog.empty_streak = 0
            prog.last_hit_date = d
            prog.last_result = "hit"
            prog.last_checked_at = datetime.now(tz=UTC).isoformat()

    async def record_empty(self, tribunal: str) -> bool:
        """Record an authoritative empty.  Returns ``True`` if tribunal just stopped."""
        async with self._lock:
            prog = self._tribunals[tribunal]
            prog.empty_streak += 1
            prog.last_result = "empty"
            prog.last_checked_at = datetime.now(tz=UTC).isoformat()
            if prog.empty_streak >= STOP_THRESHOLD:
                prog.stopped = True
                return True
            return False

    async def record_error(self, tribunal: str) -> None:
        """Record a non-authoritative error (does NOT increment streak)."""
        async with self._lock:
            prog = self._tribunals[tribunal]
            prog.last_result = "error"
            prog.last_checked_at = datetime.now(tz=UTC).isoformat()

    async def advance_cursor(self, tribunal: str) -> None:
        """Move the cursor one day backward."""
        async with self._lock:
            prog = self._tribunals[tribunal]
            prog.cursor_date -= timedelta(days=1)

    async def reset_tribunal(self, tribunal: str) -> bool:
        """Reset a stopped tribunal.  Returns ``True`` if it was found."""
        async with self._lock:
            if tribunal in self._tribunals:
                prog = self._tribunals[tribunal]
                prog.stopped = False
                prog.empty_streak = 0
                return True
            return False

    async def ensure_cursor_at_least(self, tribunal: str, min_date: date) -> bool:
        """Advance the tribunal's cursor to *min_date* if it is older.

        Also un-stops the tribunal when advanced, since new dates may have
        publications.  Returns ``True`` if the cursor was changed.
        """
        async with self._lock:
            if tribunal not in self._tribunals:
                return False
            prog = self._tribunals[tribunal]
            if prog.cursor_date < min_date:
                prog.cursor_date = min_date
                if prog.stopped:
                    prog.stopped = False
                    prog.empty_streak = 0
                return True
            return False

    def get_all_progress(self) -> dict[str, TribunalProgress]:
        """Return a snapshot of all tribunal progress (not locked — read-only use)."""
        return dict(self._tribunals)

    # ── Serialisation ────────────────────────────────────────────────

    def to_dict(self) -> dict[str, object]:
        return {
            "version": 1,
            "updated_at": datetime.now(tz=UTC).isoformat(),
            "tribunals": {k: v.to_dict() for k, v in self._tribunals.items()},
        }

    @classmethod
    def from_dict(cls, data: dict[str, object]) -> BackfillState:
        state = cls()
        tribunals = data.get("tribunals")
        if isinstance(tribunals, dict):
            for code, raw in tribunals.items():
                if isinstance(code, str) and isinstance(raw, dict):
                    try:
                        state._tribunals[code] = TribunalProgress.from_dict(raw)
                    except (ValueError, TypeError):
                        log.warning("backfill_state_skip_entry", tribunal=code)
        return state


def load_backfill_state(path: Path | None) -> BackfillState:
    """Load backfill state from *path*, returning empty state on any error."""
    if path is None or not path.is_file():
        log.info("backfill_state_miss", path=str(path))
        return BackfillState()
    try:
        raw: dict[str, object] = json.loads(path.read_text(encoding="utf-8"))
        state = BackfillState.from_dict(raw)
        log.info(
            "backfill_state_loaded",
            path=str(path),
            tribunals=len(state._tribunals),
        )
        return state
    except (json.JSONDecodeError, OSError) as exc:
        log.warning("backfill_state_corrupt", path=str(path), error=str(exc))
        return BackfillState()


def save_backfill_state(state: BackfillState, path: Path | None) -> None:
    """Persist backfill state.  No-op when *path* is ``None``."""
    if path is None:
        return
    path.parent.mkdir(parents=True, exist_ok=True)
    path.write_text(json.dumps(state.to_dict(), indent=2) + "\n", encoding="utf-8")


# ── Backfill config & summary ────────────────────────────────────────


@dataclass
class BackfillConfig:
    start_date: date
    lower_bound: date | None
    tribunal: str | None
    deadline_minutes: int
    max_items: int
    workers: int
    backfill_state_file: Path | None
    state_file: Path | None
    djen_proxy_url: str
    ia_auth: str
    dry_run: bool


@dataclass
class BackfillSummary:
    hits: int = 0
    empties: int = 0
    errors: int = 0
    tribunals_scanned: int = 0
    tribunals_stopped: int = 0
    tribunals_skipped_stopped: int = 0
    _lock: asyncio.Lock = field(default_factory=asyncio.Lock, repr=False)

    async def inc_hit(self) -> None:
        async with self._lock:
            self.hits += 1

    async def inc_empty(self) -> None:
        async with self._lock:
            self.empties += 1

    async def inc_error(self) -> None:
        async with self._lock:
            self.errors += 1

    async def inc_stopped(self) -> None:
        async with self._lock:
            self.tribunals_stopped += 1

    async def inc_skipped_stopped(self) -> None:
        async with self._lock:
            self.tribunals_skipped_stopped += 1

    async def inc_scanned(self) -> None:
        async with self._lock:
            self.tribunals_scanned += 1


# ── Single-date processing ───────────────────────────────────────────


async def backfill_process_date(
    client: httpx.AsyncClient,
    breaker: CircuitBreaker,
    tribunal: str,
    d: date,
    config: BackfillConfig,
    bstate: BackfillState,
    ia_state: State,
    summary: BackfillSummary,
) -> str:
    """Process one (tribunal, date) for backfill.

    Returns ``"hit"``, ``"empty"``, or ``"error"``.
    """
    # Fast path: already on IA
    status = ia_state.get_status(d, tribunal)
    if status == "uploaded":
        await bstate.record_hit(tribunal, d)
        await summary.inc_hit()
        return "hit"
    if status == "absent":
        stopped = await bstate.record_empty(tribunal)
        await summary.inc_empty()
        if stopped:
            await summary.inc_stopped()
        return "empty"

    # Circuit breaker guard
    if not await breaker.allow_request():
        await bstate.record_error(tribunal)
        await summary.inc_error()
        return "error"

    if config.dry_run:
        log.info("backfill_dry_run", tribunal=tribunal, date=d.isoformat())
        await bstate.record_hit(tribunal, d)
        await summary.inc_hit()
        return "hit"

    # Fetch from DJEN
    zip_path: Path | None = None
    try:
        zip_url = await get_caderno_url(client, config.djen_proxy_url, tribunal, d)
        zip_path = await download_zip(client, zip_url)
    except DJENNotFound as exc:
        # Authoritative empty — upload absent marker
        log.info(
            "backfill_empty",
            tribunal=tribunal,
            date=d.isoformat(),
            status_code=exc.status_code,
        )
        try:
            resp = await upload_absent_marker(
                client,
                d,
                tribunal,
                exc.status_code,
                exc.reason,
                config.ia_auth,
            )
            if resp.status_code < 400:
                await breaker.record_success()
                await ia_state.mark(d, tribunal, ItemStatus.ABSENT)
                stopped = await bstate.record_empty(tribunal)
                await summary.inc_empty()
                if stopped:
                    await summary.inc_stopped()
                return "empty"
            await breaker.record_failure()
        except httpx.HTTPError:
            await breaker.record_failure()
        await bstate.record_error(tribunal)
        await summary.inc_error()
        return "error"
    except httpx.HTTPError as exc:
        log.error(
            "backfill_download_error",
            tribunal=tribunal,
            date=d.isoformat(),
            error=str(exc),
        )
        await bstate.record_error(tribunal)
        await summary.inc_error()
        return "error"

    # Upload to IA
    try:
        resp = await upload_zip(client, d, tribunal, zip_path, config.ia_auth)
        if resp.status_code < 400:
            await breaker.record_success()
            await ia_state.mark(d, tribunal, ItemStatus.UPLOADED)
            await bstate.record_hit(tribunal, d)
            await summary.inc_hit()
            return "hit"
        log.error(
            "backfill_upload_failed",
            tribunal=tribunal,
            date=d.isoformat(),
            status=resp.status_code,
        )
        await breaker.record_failure()
    except httpx.HTTPError as exc:
        log.error(
            "backfill_upload_error",
            tribunal=tribunal,
            date=d.isoformat(),
            error=str(exc),
        )
        await breaker.record_failure()

    await bstate.record_error(tribunal)
    await summary.inc_error()
    return "error"
    # zip_path cleanup is handled by the caller (backfill_tribunal)
    # since we always return before reaching here after the try/finally below.


# ── Per-tribunal scan loop ───────────────────────────────────────────


async def backfill_tribunal(
    client: httpx.AsyncClient,
    breaker: CircuitBreaker,
    tribunal: str,
    config: BackfillConfig,
    bstate: BackfillState,
    ia_state: State,
    deadline: float,
    summary: BackfillSummary,
) -> None:
    """Scan one tribunal backward until stopped, lower-bound, or deadline."""
    prog = await bstate.get_or_init(tribunal, config.start_date)

    if prog.stopped:
        log.info("backfill_skipped_stopped", tribunal=tribunal)
        await summary.inc_skipped_stopped()
        return

    await summary.inc_scanned()
    items_processed = 0

    while config.lower_bound is None or prog.cursor_date >= config.lower_bound:
        # Deadline guard
        if time.monotonic() > deadline - 30:
            log.info("backfill_deadline_reached", tribunal=tribunal)
            break

        # Max items guard
        if config.max_items and items_processed >= config.max_items:
            break

        current_date = prog.cursor_date

        log.debug(
            "backfill_date",
            tribunal=tribunal,
            date=current_date.isoformat(),
            empty_streak=prog.empty_streak,
        )

        zip_path: Path | None = None
        try:
            await backfill_process_date(
                client,
                breaker,
                tribunal,
                current_date,
                config,
                bstate,
                ia_state,
                summary,
            )
        finally:
            if zip_path is not None:
                zip_path.unlink(missing_ok=True)

        await bstate.advance_cursor(tribunal)
        items_processed += 1

        # Checkpoint after each date
        save_backfill_state(bstate, config.backfill_state_file)

        # Check if just stopped
        if prog.stopped:
            log.info(
                "backfill_tribunal_stopped",
                tribunal=tribunal,
                empty_streak=prog.empty_streak,
                cursor=prog.cursor_date.isoformat(),
            )
            break


# ── Main orchestration ───────────────────────────────────────────────


async def run_backfill(config: BackfillConfig) -> int:
    """Execute the backfill pipeline.  Returns the process exit code."""
    from djen_backup.runner import validate_tribunal
    from djen_backup.state import load_state, save_state
    from djen_backup.tribunais import get_tribunal_list

    deadline = time.monotonic() + config.deadline_minutes * 60
    bstate = load_backfill_state(config.backfill_state_file)
    ia_state = load_state(config.state_file)

    timeout = httpx.Timeout(connect=10.0, read=120.0, write=120.0, pool=10.0)
    async with httpx.AsyncClient(timeout=timeout, follow_redirects=True) as client:
        # 1. Tribunal list
        all_tribunals = await get_tribunal_list(client, config.djen_proxy_url)
        if config.tribunal:
            validate_tribunal(config.tribunal)
            all_tribunals = [config.tribunal]

        # 2. Advance stale cursors so new dates are always checked
        for t in all_tribunals:
            advanced = await bstate.ensure_cursor_at_least(t, config.start_date)
            if advanced:
                log.info(
                    "cursor_auto_advanced",
                    tribunal=t,
                    new_cursor=config.start_date.isoformat(),
                )

        # 3. Process tribunals
        summary = BackfillSummary()
        breaker = CircuitBreaker(threshold=5, recovery_timeout=60.0)

        queue: asyncio.Queue[str] = asyncio.Queue()
        for t in all_tribunals:
            queue.put_nowait(t)

        async def _worker() -> None:
            while not queue.empty():
                if time.monotonic() > deadline - 30:
                    break
                try:
                    tribunal = queue.get_nowait()
                except asyncio.QueueEmpty:
                    break
                await backfill_tribunal(
                    client,
                    breaker,
                    tribunal,
                    config,
                    bstate,
                    ia_state,
                    deadline,
                    summary,
                )
                queue.task_done()

        workers = [asyncio.create_task(_worker()) for _ in range(config.workers)]
        await asyncio.gather(*workers)

    # 4. Save state
    save_backfill_state(bstate, config.backfill_state_file)
    save_state(ia_state, config.state_file)

    # 5. Summary
    log.info(
        "backfill_complete",
        tribunals_scanned=summary.tribunals_scanned,
        tribunals_stopped=summary.tribunals_stopped,
        tribunals_skipped_stopped=summary.tribunals_skipped_stopped,
        hits=summary.hits,
        empties=summary.empties,
        errors=summary.errors,
    )

    return 0
